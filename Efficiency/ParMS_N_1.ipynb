{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uG6SJN7fZa4_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import copy\n",
        "from tqdm import trange\n",
        "from torchsummary import summary\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.optim import SGD, Optimizer\n",
        "from typing import List\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VzJRdXpobgBG"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for training\n",
        "num_rounds = 50\n",
        "local_rounds = 10\n",
        "num_clients = 10  # Total number of clients\n",
        "num_selected = 10  # Number of selected clients per round\n",
        "local_bs = 10\n",
        "lr = 0.001\n",
        "num_channels = 3\n",
        "num_classes = 10\n",
        "test_bs = 128\n",
        "gpu = 1\n",
        "gamma = 0.1\n",
        "milestones = [0.5 * num_rounds, 0.75 * num_rounds]\n",
        "\n",
        "momentum = 0.9\n",
        "weight_decay = 0.00001\n",
        "mu = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PYbUdZkjbmZH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=4)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ResNet9\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNet9(nn.Module):\n",
        "    def __init__(\n",
        "            self, \n",
        "            in_channels, \n",
        "            num_classes):\n",
        "        super(ResNet9, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d((1,1)), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512,num_classes))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CIFAR10_truncated(Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        cifar_dataobj = datasets.CIFAR10(self.root, self.train, self.transform, self.target_transform, self.download)\n",
        "\n",
        "        data = np.array(cifar_dataobj.data)\n",
        "        target = np.array(cifar_dataobj.targets)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_pK9897Lb86S"
      },
      "outputs": [],
      "source": [
        "class DatasetSplit(Dataset):\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.targets = dataset.targets\n",
        "        self.idxs = list(idxs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cRVoTdg5cowo"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]], std=[x / 255.0 for x in [63.0, 62.1, 66.7]])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApAnVijabpCO",
        "outputId": "ead7b612-e8d1-48a4-932a-3104e1555c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# CIFAR10 Data loading\n",
        "train_dataset = CIFAR10_truncated('./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = CIFAR10_truncated('./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "X_train, y_train = train_dataset.data, train_dataset.target\n",
        "X_test, y_test = test_dataset.data, test_dataset.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7WqBz6HobwuF"
      },
      "outputs": [],
      "source": [
        "def record_net_data_stats(y_train, net_dataidx_map):\n",
        "\n",
        "    net_cls_counts = {}\n",
        "\n",
        "    for net_i, dataidx in net_dataidx_map.items():\n",
        "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
        "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
        "        net_cls_counts[net_i] = tmp\n",
        "\n",
        "    #print('Data statistics: %s' % str(net_cls_counts))\n",
        "\n",
        "    return net_cls_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for IID case\n",
        "def generate_iid_cifar(X_train,y_train, num_of_clients):\n",
        "    \"\"\"\n",
        "    Sample I.I.D. client data from CIFAR10 dataset\n",
        "    :param n_nets: Number of clients\n",
        "    :return: Tuple containing train and test datasets, data index map for each client, and train data class counts\n",
        "    \"\"\"\n",
        "    \n",
        "    n_train = X_train.shape[0]\n",
        "\n",
        "    # Shuffle and partition the data\n",
        "    idxs = np.arange(n_train)\n",
        "    np.random.shuffle(idxs)\n",
        "\n",
        "    net_data_idx_map = {}\n",
        "    batch_idxs = np.array_split(idxs, num_of_clients)\n",
        "\n",
        "    for i in range(num_of_clients):\n",
        "        net_data_idx_map[i] = batch_idxs[i]\n",
        "\n",
        "    traindata_class_counts = record_net_data_stats(y_train, net_data_idx_map)\n",
        "\n",
        "    return net_data_idx_map, traindata_class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_noniid_cifar(X_train,y_train, num_of_clients, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Sample non I.I.D. client data from CIFAR10 dataset\n",
        "    :param dataset: \n",
        "    :param num_users: \n",
        "    :return: \n",
        "    \"\"\"\n",
        "\n",
        "    n_train = len(X_train.shape)\n",
        "\n",
        "    min_size = 0\n",
        "    K = 10\n",
        "    N = len(y_train)\n",
        "    net_dataidx_map = {}\n",
        "\n",
        "    while min_size < 10:\n",
        "        idx_batch = [[] for _ in range(num_of_clients)]\n",
        "        for k in range(K):\n",
        "            idx_k = np.where(y_train == k)[0]\n",
        "            np.random.shuffle(idx_k)\n",
        "            proportions = np.random.dirichlet(np.repeat(alpha, num_of_clients))\n",
        "            ## Balance\n",
        "            proportions = np.array([p*(len(idx_j)<N/num_of_clients) for p,idx_j in zip(proportions,idx_batch)])\n",
        "            proportions = proportions/proportions.sum()\n",
        "            proportions = (np.cumsum(proportions)*len(idx_k)).astype(int)[:-1]\n",
        "            idx_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_batch,np.split(idx_k,proportions))]\n",
        "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
        "\n",
        "    for j in range(num_of_clients):\n",
        "        np.random.shuffle(idx_batch[j])\n",
        "        net_dataidx_map[j] = idx_batch[j]\n",
        "    traindata_class_counts = record_net_data_stats(y_train, net_dataidx_map)\n",
        "\n",
        "    return net_dataidx_map, traindata_class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "noniid_dataidx_map, noniid_traindata_cls_counts = generate_noniid_cifar(X_train,y_train, num_clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "J0okEWXv45np"
      },
      "outputs": [],
      "source": [
        "# from torchviz import make_dot\n",
        "\n",
        "# # Sample input to model for visualization\n",
        "# sample_input = torch.randn(1, num_channels, 32, 32).to(device)\n",
        "# model_vis = LeNet(num_classes).to(device)\n",
        "\n",
        "# # Visualize the model\n",
        "# model_dot = make_dot(global_model(sample_input), params=dict(list(global_model.named_parameters())))\n",
        "# model_dot.render(\"model_architecture\", format=\"png\")  # Saves the diagram as PNG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Client training function\n",
        "def client_train(global_mod:nn.Module, net: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    local_rounds: int,\n",
        "    proximal_mu: float,\n",
        "    learning_rate: float,\n",
        "    momentum: float,\n",
        "    weight_decay: float):\n",
        "    \n",
        "    epoch_loss = []\n",
        "    epoch_acc = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = SGD(\n",
        "        net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay\n",
        "    )\n",
        "    global_params = [param.detach().clone() for param in global_mod.parameters()]\n",
        "    net.train()\n",
        "    for _ in range(local_rounds):\n",
        "        batch_loss = []\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "            loss = criterion(output, target)\n",
        "            proximal_term = 0.0\n",
        "            for param, global_param in zip(net.parameters(), global_params):\n",
        "                proximal_term += torch.norm(param - global_param) ** 2\n",
        "            loss += (proximal_mu / 2) * proximal_term\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_train = pred.eq(target.data.view_as(pred))\n",
        "            accuracy_train = torch.mean(correct_train.type(torch.FloatTensor))\n",
        "            epoch_acc.append(accuracy_train.item())\n",
        "\n",
        "        epoch_loss.append(sum(batch_loss) / len(batch_loss))\n",
        "    return net.state_dict(), sum(epoch_loss) / len(epoch_loss), sum(epoch_acc) / len(epoch_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bAXYEu_Db4jX"
      },
      "outputs": [],
      "source": [
        "# 'FedAvg' aggregation\n",
        "def FedAvg(w):\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for k in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[k] += w[i][k]\n",
        "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
        "    return w_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Kx1_Y0onb_Qu"
      },
      "outputs": [],
      "source": [
        "# Evaluate on Test dataset\n",
        "def evaluate(global_model, datatest, test_bs, device):\n",
        "    global_model.eval()\n",
        "    # testing\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    data_loader = DataLoader(datatest, batch_size=test_bs)\n",
        "    with torch.no_grad():\n",
        "        for data, target in data_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            log_probs = global_model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.cross_entropy(log_probs,\n",
        "                                         target, reduction='sum').item()\n",
        "            # get the index of the max log-probability\n",
        "            y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
        "            correct += y_pred.eq(target.data.view_as(y_pred)\n",
        "                                 ).long().cpu().sum()\n",
        "\n",
        "        test_loss /= len(data_loader.dataset)\n",
        "        accuracy = 100.00 * correct.item() / len(data_loader.dataset)\n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and synchronize models###\n",
        "global_model = ResNet9(\n",
        "    in_channels=num_channels, num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "clients_models = {i: ResNet9(in_channels=num_channels, num_classes=num_classes).to(device) for i in range(num_clients)}\n",
        "optimizers={}\n",
        "for key, model in clients_models.items():\n",
        "   optimizers[key] =  torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "schedulers={}\n",
        "for key, optimizer in optimizers.items():\n",
        "   schedulers[key] =  torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clients_models.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round Test, Test Loss: 2.3054, Test Accuracy: 8.83%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on test dataset for each round\n",
        "cur_auc, test_loss = evaluate(\n",
        "   global_model, test_dataset, test_bs, device)\n",
        "print(f'Round Test, Test Loss: {test_loss:.4f}, Test Accuracy: {cur_auc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round Test, Test Loss: 2.3042, Test Accuracy: 7.57%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on test dataset for each round\n",
        "cur_auc, test_loss = evaluate(\n",
        "    clients_models[0], test_dataset, test_bs, device)\n",
        "print(f'Round Test, Test Loss: {test_loss:.4f}, Test Accuracy: {cur_auc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in clients_models.values():\n",
        "  model.load_state_dict(global_model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round Test, Test Loss: 2.3054, Test Accuracy: 8.83%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation on test dataset for each round\n",
        "cur_auc, test_loss = evaluate(\n",
        "    clients_models[0], test_dataset, test_bs, device)\n",
        "print(f'Round Test, Test Loss: {test_loss:.4f}, Test Accuracy: {cur_auc:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKcIqAX-cDBe",
        "outputId": "430da6c5-5b94-4d56-b7de-ffbc0f17c9b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [18:56<00:00, 113.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 1, Train loss: 1.5713, Test Loss: 2.4650, Test Accuracy: 11.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [23:26<00:00, 140.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 2, Train loss: 1.2178, Test Loss: 1.8194, Test Accuracy: 34.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [20:10<00:00, 121.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 3, Train loss: 0.9047, Test Loss: 1.4026, Test Accuracy: 51.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:42<00:00, 58.27s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 4, Train loss: 0.7006, Test Loss: 1.1437, Test Accuracy: 63.17%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:44<00:00, 52.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 5, Train loss: 0.5738, Test Loss: 0.8859, Test Accuracy: 71.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:39<00:00, 51.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 6, Train loss: 0.4906, Test Loss: 0.7659, Test Accuracy: 75.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:35<00:00, 51.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 7, Train loss: 0.4220, Test Loss: 0.6046, Test Accuracy: 80.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:37<00:00, 51.75s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 8, Train loss: 0.3770, Test Loss: 0.6129, Test Accuracy: 81.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:39<00:00, 51.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 9, Train loss: 0.3413, Test Loss: 0.5621, Test Accuracy: 82.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:39<00:00, 51.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 10, Train loss: 0.3016, Test Loss: 0.5316, Test Accuracy: 84.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:38<00:00, 51.84s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 11, Train loss: 0.2805, Test Loss: 0.4772, Test Accuracy: 85.69%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:39<00:00, 51.93s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 12, Train loss: 0.2625, Test Loss: 0.4759, Test Accuracy: 86.08%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:36<00:00, 51.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 13, Train loss: 0.2411, Test Loss: 0.4702, Test Accuracy: 86.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:36<00:00, 51.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 14, Train loss: 0.2261, Test Loss: 0.4485, Test Accuracy: 86.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:35<00:00, 51.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 15, Train loss: 0.2152, Test Loss: 0.4440, Test Accuracy: 87.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:34<00:00, 51.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 16, Train loss: 0.1933, Test Loss: 0.4207, Test Accuracy: 88.16%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:37<00:00, 51.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 17, Train loss: 0.1831, Test Loss: 0.4357, Test Accuracy: 87.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:34<00:00, 51.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 18, Train loss: 0.1711, Test Loss: 0.4140, Test Accuracy: 88.60%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:32<00:00, 51.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 19, Train loss: 0.1654, Test Loss: 0.4149, Test Accuracy: 88.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:33<00:00, 51.36s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 20, Train loss: 0.1588, Test Loss: 0.4006, Test Accuracy: 88.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:35<00:00, 51.56s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 21, Train loss: 0.1428, Test Loss: 0.4148, Test Accuracy: 88.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:34<00:00, 51.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 22, Train loss: 0.1411, Test Loss: 0.3957, Test Accuracy: 89.28%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:33<00:00, 51.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 23, Train loss: 0.1349, Test Loss: 0.3893, Test Accuracy: 89.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:41<00:00, 52.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 24, Train loss: 0.1248, Test Loss: 0.3885, Test Accuracy: 89.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:31<00:00, 51.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 25, Train loss: 0.1245, Test Loss: 0.3671, Test Accuracy: 89.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:32<00:00, 51.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 26, Train loss: 0.1173, Test Loss: 0.3857, Test Accuracy: 89.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:31<00:00, 51.15s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 27, Train loss: 0.1105, Test Loss: 0.3684, Test Accuracy: 90.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:29<00:00, 50.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 28, Train loss: 0.1043, Test Loss: 0.3549, Test Accuracy: 90.02%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:28<00:00, 50.89s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 29, Train loss: 0.0989, Test Loss: 0.3925, Test Accuracy: 89.80%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:29<00:00, 50.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 30, Train loss: 0.0980, Test Loss: 0.3861, Test Accuracy: 89.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:30<00:00, 51.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 31, Train loss: 0.0954, Test Loss: 0.3739, Test Accuracy: 90.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [08:56<00:00, 53.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 32, Train loss: 0.0909, Test Loss: 0.3697, Test Accuracy: 90.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:20<00:00, 56.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 33, Train loss: 0.0937, Test Loss: 0.3740, Test Accuracy: 90.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:17<00:00, 55.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 34, Train loss: 0.0854, Test Loss: 0.3601, Test Accuracy: 90.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:20<00:00, 56.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 35, Train loss: 0.0870, Test Loss: 0.3797, Test Accuracy: 90.44%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:21<00:00, 56.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 36, Train loss: 0.0876, Test Loss: 0.3672, Test Accuracy: 90.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:19<00:00, 55.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 37, Train loss: 0.0837, Test Loss: 0.3865, Test Accuracy: 90.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:20<00:00, 56.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 38, Train loss: 0.0751, Test Loss: 0.3728, Test Accuracy: 90.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:18<00:00, 55.83s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 39, Train loss: 0.0732, Test Loss: 0.3792, Test Accuracy: 90.87%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:21<00:00, 56.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 40, Train loss: 0.0813, Test Loss: 0.3660, Test Accuracy: 90.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:19<00:00, 55.90s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 41, Train loss: 0.0674, Test Loss: 0.3531, Test Accuracy: 91.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:18<00:00, 55.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 42, Train loss: 0.0666, Test Loss: 0.3721, Test Accuracy: 90.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:22<00:00, 56.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 43, Train loss: 0.0639, Test Loss: 0.3769, Test Accuracy: 90.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:20<00:00, 56.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 44, Train loss: 0.0724, Test Loss: 0.3684, Test Accuracy: 90.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:19<00:00, 55.97s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 45, Train loss: 0.0664, Test Loss: 0.3752, Test Accuracy: 91.26%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:19<00:00, 55.94s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 46, Train loss: 0.0556, Test Loss: 0.3668, Test Accuracy: 91.16%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:17<00:00, 55.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 47, Train loss: 0.0574, Test Loss: 0.3586, Test Accuracy: 91.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:15<00:00, 55.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 48, Train loss: 0.0625, Test Loss: 0.3636, Test Accuracy: 91.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:24<00:00, 56.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 49, Train loss: 0.0563, Test Loss: 0.3605, Test Accuracy: 91.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:12<00:00, 55.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round 50, Train loss: 0.0499, Test Loss: 0.3492, Test Accuracy: 91.63%\n"
          ]
        }
      ],
      "source": [
        "global_model.train()\n",
        "\n",
        "best_auc = 0\n",
        "best_round = 0\n",
        "loss_train = []\n",
        "loss_test = []\n",
        "acc_train = []\n",
        "acc_test= []\n",
        "clients_selected = {}\n",
        "# selected_clients = np.random.choice(range(num_clients), num_selected, replace=False)\n",
        "\n",
        "# local_indices = generate_iid_cifar(train_dataset, num_clients)\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    local_weights, local_losses, local_acc = [], [], []\n",
        "\n",
        "    # Select a subset of clients to train this round\n",
        "    # for selected_client in selected_clients:\n",
        "    #     print(\"clients sleected \"+str(selected_client))\n",
        "    selected_clients = list(np.random.choice(range(num_clients), num_selected, replace=False))\n",
        "    clients_selected[round] = selected_clients\n",
        "    for i in trange(num_selected):\n",
        "        local_loader = DataLoader(CIFAR10_truncated(\n",
        "        './data', dataidxs=noniid_dataidx_map[i], train=True, transform=transform_train), batch_size=local_bs, shuffle=True)\n",
        "\n",
        "        # Train on local data\n",
        "        # w, loss, acc = client_train(\n",
        "        #     clients_models[i], local_loader, optimizers[i], schedulers[i], criterion, local_rounds)\n",
        "        w, loss, acc = client_train(global_model, clients_models[i], local_loader, device, local_rounds, mu, lr, momentum, weight_decay)\n",
        "\n",
        "        # Collect local model weights\n",
        "        local_weights.append(w)\n",
        "        local_losses.append(loss)\n",
        "        local_acc.append(acc)\n",
        "\n",
        "    # Aggregate local weights to update global model\n",
        "    global_weights = FedAvg(local_weights)\n",
        "        # with open('readme.txt', 'a') as f:\n",
        "        #     f.write('Weights and bias of client '+str(client)+': \\n'+str(w))\n",
        "        # print(f\"Local weight of {client} is: \", w)\n",
        "    \n",
        "    # copy weight to global model\n",
        "    global_model.load_state_dict(global_weights)\n",
        "    for model in clients_models.values():\n",
        "        model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Calulate loss\n",
        "    loss_avg = sum(local_losses) / len(local_losses)\n",
        "    # print('Round {:3d}, Train loss {:.3f}'.format(round, loss_avg))\n",
        "    loss_train.append(loss_avg)\n",
        "    acc_train.append(100 * sum(local_acc) / len(local_acc))\n",
        "\n",
        "    # Evaluation on test dataset for each round\n",
        "    cur_auc, test_loss = evaluate(\n",
        "        global_model, test_dataset, test_bs, device)\n",
        "    loss_test.append(test_loss)\n",
        "    acc_test.append(cur_auc)\n",
        "    print(f'Round {round+1}, Train loss: {loss_avg:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {cur_auc:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMu4zjVscHpL"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "global_model.eval()\n",
        "train_acc, train_loss = evaluate(\n",
        "    global_model, train_dataset, test_bs, device)\n",
        "test_acc, test_loss = evaluate(\n",
        "    global_model, test_dataset, test_bs, device)\n",
        "print(\"Training accuracy: {:.2f}%\".format(train_acc))\n",
        "print(\"Testing accuracy: {:.2f}%\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "torch.save(global_model, 'FL_model_resnet9_24_06.pth')\n",
        "\n",
        "# # To load the entire model\n",
        "# model = torch.load('model_complete.pth')\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save only the state dictionary\n",
        "torch.save(model.state_dict(), 'FL_model_resnet9_state_dict.pth')\n",
        "\n",
        "# # To load the state dictionary, you need to re-instantiate the model first\n",
        "# model = ResNet18()\n",
        "# model.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ccuh6WFzCPdj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8, 6, 3, 2, 0, 7, 9, 1, 4, 5])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('FL_model_resnet9_overfit_train_accuracy.txt', 'w') as file:\n",
        "    # Write each value on a new line\n",
        "    file.write(f\"{acc_train}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('FL_model_resnet9_overfit_test_accuracy.txt', 'w') as file:\n",
        "    # Write each value on a new line\n",
        "    file.write(f\"{acc_test}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('FL_model_resnet9_overfit_train_loss.txt', 'w') as file:\n",
        "    # Write each value on a new line\n",
        "    file.write(f\"{loss_train}\\n\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('FL_model_resnet9_overfit_test_loss.txt', 'w') as file:\n",
        "    # Write each value on a new line\n",
        "    file.write(f\"{loss_test}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.undefined"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
