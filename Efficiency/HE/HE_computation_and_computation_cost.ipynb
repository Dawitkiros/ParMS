{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTqEmx6LS7Bo",
        "outputId": "6f8b6f12-97bd-446c-f630-43c39b84d4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tenseal\n",
            "  Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Downloading tenseal-0.3.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenseal\n",
            "Successfully installed tenseal-0.3.14\n"
          ]
        }
      ],
      "source": [
        "!pip install tenseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uKmH5PWzS6DY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import tenseal as ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8tZ6juuTn9M_"
      },
      "outputs": [],
      "source": [
        "import tenseal as ts\n",
        "\n",
        "def context():\n",
        "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "    context.global_scale = pow(2, 52)\n",
        "    context.generate_galois_keys()\n",
        "    return context\n",
        "\n",
        "context = context()\n",
        "\n",
        "# Serialize context to a file\n",
        "with open(\"context.tenseal\", \"wb\") as f:\n",
        "    f.write(context.serialize())\n",
        "\n",
        "# Make context public and serialize the public context\n",
        "context.make_context_public()\n",
        "with open(\"public_context.tenseal\", \"wb\") as f:\n",
        "    f.write(context.serialize())\n",
        "\n",
        "# Deserialize context from a file\n",
        "with open(\"context.tenseal\", \"rb\") as f:\n",
        "    context = ts.context_from(f.read())\n",
        "\n",
        "# Deserialize public context from a file\n",
        "with open(\"public_context.tenseal\", \"rb\") as f:\n",
        "    public_context = ts.context_from(f.read())\n",
        "\n",
        "# Optionally, you can make the public context again\n",
        "public_context.make_context_public()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U2UwoLsVoFYy"
      },
      "outputs": [],
      "source": [
        "# Encrypt data with the public context\n",
        "def encrypt_data(public_context, data):\n",
        "    enc_data = ts.ckks_vector(public_context, data)\n",
        "    return enc_data\n",
        "\n",
        "data = [1.0, 2.0, 3.0, 4.0]\n",
        "enc_data = encrypt_data(public_context, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhGjhfx-oIt2",
        "outputId": "c6102b76-d4c2-46b8-ee4c-4f54e26b82fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decrypted data: [0.999999999999791, 2.0000000000001656, 3.0000000000006466, 3.999999999999131]\n"
          ]
        }
      ],
      "source": [
        "import tenseal as ts\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Function to create context with secret key\n",
        "def create_context():\n",
        "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
        "    context.global_scale = pow(2, 52)\n",
        "    context.generate_galois_keys()\n",
        "    return context\n",
        "\n",
        "# Create and save context\n",
        "context = create_context()\n",
        "\n",
        "# Serialize and save context with secret key using pickle\n",
        "with open(\"context.pkl\", \"wb\") as f:\n",
        "    pickle.dump(context.serialize(save_secret_key=True), f)\n",
        "\n",
        "# Make the context public and save it using pickle\n",
        "context.make_context_public()\n",
        "with open(\"public_context.pkl\", \"wb\") as f:\n",
        "    pickle.dump(context.serialize(), f)\n",
        "\n",
        "# Function to encrypt data\n",
        "def encrypt_data(context, data):\n",
        "    return ts.ckks_vector(context, data)\n",
        "\n",
        "# Function to decrypt data\n",
        "def decrypt_data(context, enc_data):\n",
        "    enc_data.link_context(context)\n",
        "    dec_data = enc_data.decrypt()\n",
        "    return dec_data\n",
        "\n",
        "# Encrypt some data\n",
        "data = [1.0, 2.0, 3.0, 4.0]\n",
        "enc_data = encrypt_data(context, data)\n",
        "\n",
        "# Save the encrypted data using pickle\n",
        "with open(\"encrypted_data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(enc_data.serialize(), f)\n",
        "\n",
        "# Load context with secret key using pickle\n",
        "with open(\"context.pkl\", \"rb\") as f:\n",
        "    context = ts.context_from(pickle.load(f))\n",
        "\n",
        "# Load encrypted data using pickle\n",
        "with open(\"encrypted_data.pkl\", \"rb\") as f:\n",
        "    enc_data = ts.ckks_vector_from(context, pickle.load(f))\n",
        "\n",
        "# Decrypt the data\n",
        "dec_data = decrypt_data(context, enc_data)\n",
        "print(\"Decrypted data:\", dec_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H84ZhymV42j4"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "class PartialModelHandler:\n",
        "    def __init__(self, num_segments: int):\n",
        "        self.num_segments = num_segments\n",
        "\n",
        "    def flatten_resnet_parameters(self, state_dict):\n",
        "        \"\"\"\n",
        "        Flatten and concatenate all parameters from a state_dict into a single vector.\n",
        "        \"\"\"\n",
        "        flat_params = torch.cat([p.view(-1).float() for p in state_dict.values()])\n",
        "        return flat_params\n",
        "\n",
        "    def reconstruct_parameters(self, flat_params, shapes, sizes, trained_weights):\n",
        "        \"\"\"\n",
        "        Reconstruct the original tensors from a flattened parameter tensor.\n",
        "        \"\"\"\n",
        "        reconstructed_params = OrderedDict()\n",
        "        offset = 0\n",
        "        for key in shapes:\n",
        "            num_elements = sizes[key]\n",
        "            param_slice = flat_params[offset:offset + num_elements]\n",
        "            reconstructed_params[key] = param_slice.view(shapes[key]).to(trained_weights[key].dtype)\n",
        "            offset += num_elements\n",
        "        return reconstructed_params\n",
        "\n",
        "    def segment_resnet_parameters(self, flat_params):\n",
        "        \"\"\"\n",
        "        Divide the flat parameters into equal segments, ensuring all elements are included.\n",
        "        \"\"\"\n",
        "        total_len = len(flat_params)\n",
        "        segment_size = total_len // self.num_segments\n",
        "        remainder = total_len % self.num_segments\n",
        "\n",
        "        segments = []\n",
        "        start = 0\n",
        "        for i in range(self.num_segments):\n",
        "            end = start + segment_size + (1 if i < remainder else 0)\n",
        "            segments.append(flat_params[start:end])\n",
        "            start = end\n",
        "\n",
        "        return segments\n",
        "\n",
        "    def preprocess_weights(self, weights: Dict):\n",
        "        \"\"\"\n",
        "        Preprocess the weights of a model to prepare for federated learning.\n",
        "        \"\"\"\n",
        "        flat_params_n = {key: self.flatten_resnet_parameters(value) for key, value in weights.items()}\n",
        "        segmented_params = {key: self.segment_resnet_parameters(flat_param) for key, flat_param in flat_params_n.items()}\n",
        "        return flat_params_n, segmented_params\n",
        "\n",
        "    def extract_shared_segments(self, clients_dict, client_shared_segments):\n",
        "        \"\"\"\n",
        "        Extract segments from each client's data based on the segments they are supposed to share.\n",
        "        \"\"\"\n",
        "        shared_data = {}\n",
        "        for client_id, segment_id in client_shared_segments.items():\n",
        "            shared_data[client_id] = {segment_id: clients_dict[client_id][segment_id]}\n",
        "        return shared_data\n",
        "\n",
        "    def aggregate_data_by_key(self, shared_data):\n",
        "        \"\"\"\n",
        "        Aggregate data received from clients by key.\n",
        "        \"\"\"\n",
        "        aggregation = {}\n",
        "        count = {}\n",
        "\n",
        "        for client_data in shared_data.values():\n",
        "            for key, values in client_data.items():\n",
        "                if key in aggregation:\n",
        "                    aggregation[key] += values\n",
        "                    count[key] += 1\n",
        "                else:\n",
        "                    aggregation[key] = values.clone()\n",
        "                    count[key] = 1\n",
        "\n",
        "        for key in aggregation.keys():\n",
        "            aggregation[key] /= count[key]\n",
        "\n",
        "        return aggregation\n",
        "\n",
        "    def handle_partial_updates(self, client_weights, client_segment_map):\n",
        "        \"\"\"\n",
        "        Handle partial updates from clients by averaging the weights.\n",
        "        \"\"\"\n",
        "        segmented_params = self.segment_resnet_parameters(self.flatten_resnet_parameters(client_weights))\n",
        "        segments_to_send = self.extract_shared_segments(segmented_params, client_segment_map)\n",
        "        return segments_to_send\n",
        "\n",
        "    def update_client_models(self, clients_segmented_params, aggregated_segments, client_segment_map):\n",
        "        \"\"\"\n",
        "        Update client models with aggregated segments and average unshared segments.\n",
        "        \"\"\"\n",
        "        updated_params = {}\n",
        "\n",
        "        for client_id, segments in clients_segmented_params.items():\n",
        "            updated_segments = []\n",
        "            shared_segment_index = client_segment_map[client_id]\n",
        "\n",
        "            for i, segment_data in enumerate(segments):\n",
        "                if i == shared_segment_index:\n",
        "                    updated_segments.append(aggregated_segments[shared_segment_index])\n",
        "                else:\n",
        "                    updated_segments.append(segment_data)\n",
        "\n",
        "            updated_params[client_id] = updated_segments\n",
        "\n",
        "        updated_client_segments = {client_id: torch.cat(segments) for client_id, segments in updated_params.items()}\n",
        "        return updated_client_segments\n",
        "\n",
        "    def rotate_shared_segments(self, client_segment_map):\n",
        "        \"\"\"\n",
        "        Rotate the segments that each client shares for the next round.\n",
        "        \"\"\"\n",
        "        for client in client_segment_map:\n",
        "            client_segment_map[client] = (client_segment_map[client] + 1) % self.num_segments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o5H5IRT05rwe"
      },
      "outputs": [],
      "source": [
        "#ResNet9\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            hidden_dims,\n",
        "            num_classes):\n",
        "        super(ResNet9, self).__init__()\n",
        "\n",
        "        self.conv1 = conv_block(input_dim, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d((1,1)),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def segment_resnet_parameters(flat_params, num_segments):\n",
        "    \"\"\"\n",
        "    Divide the flat parameters into equal segments, ensuring all elements are included.\n",
        "    \"\"\"\n",
        "    total_len = len(flat_params)\n",
        "    segment_size = total_len // num_segments\n",
        "    remainder = total_len % num_segments\n",
        "\n",
        "    segments = []\n",
        "    start = 0\n",
        "    for i in range(num_segments):\n",
        "        end = start + segment_size + (1 if i < remainder else 0)\n",
        "        segments.append(flat_params[start:end])\n",
        "        start = end\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "DWJGmXMNgd4O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ha5GaKHM59q6"
      },
      "outputs": [],
      "source": [
        "net = ResNet9(3, [], 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"SI No\", \"Layer Name\", \"Parameters Listed\"])\n",
        "    t_params = 0\n",
        "    for si_no, (name, parameter) in enumerate(model.named_parameters()):\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([si_no, name, param])\n",
        "        t_params+=param\n",
        "    print(table)\n",
        "    print(f\"Sum of trained paramters: {t_params}\")\n",
        "    return t_params"
      ],
      "metadata": {
        "id": "MwTuNunZ43TD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdSFIVrd5Drl",
        "outputId": "842a0e89-e1c8-416b-be20-0d6f7cd5429d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------------------+-------------------+\n",
            "| SI No |      Layer Name     | Parameters Listed |\n",
            "+-------+---------------------+-------------------+\n",
            "|   0   |    conv1.0.weight   |        1728       |\n",
            "|   1   |     conv1.0.bias    |         64        |\n",
            "|   2   |    conv1.1.weight   |         64        |\n",
            "|   3   |     conv1.1.bias    |         64        |\n",
            "|   4   |    conv2.0.weight   |       73728       |\n",
            "|   5   |     conv2.0.bias    |        128        |\n",
            "|   6   |    conv2.1.weight   |        128        |\n",
            "|   7   |     conv2.1.bias    |        128        |\n",
            "|   8   |   res1.0.0.weight   |       147456      |\n",
            "|   9   |    res1.0.0.bias    |        128        |\n",
            "|   10  |   res1.0.1.weight   |        128        |\n",
            "|   11  |    res1.0.1.bias    |        128        |\n",
            "|   12  |   res1.1.0.weight   |       147456      |\n",
            "|   13  |    res1.1.0.bias    |        128        |\n",
            "|   14  |   res1.1.1.weight   |        128        |\n",
            "|   15  |    res1.1.1.bias    |        128        |\n",
            "|   16  |    conv3.0.weight   |       294912      |\n",
            "|   17  |     conv3.0.bias    |        256        |\n",
            "|   18  |    conv3.1.weight   |        256        |\n",
            "|   19  |     conv3.1.bias    |        256        |\n",
            "|   20  |    conv4.0.weight   |      1179648      |\n",
            "|   21  |     conv4.0.bias    |        512        |\n",
            "|   22  |    conv4.1.weight   |        512        |\n",
            "|   23  |     conv4.1.bias    |        512        |\n",
            "|   24  |   res2.0.0.weight   |      2359296      |\n",
            "|   25  |    res2.0.0.bias    |        512        |\n",
            "|   26  |   res2.0.1.weight   |        512        |\n",
            "|   27  |    res2.0.1.bias    |        512        |\n",
            "|   28  |   res2.1.0.weight   |      2359296      |\n",
            "|   29  |    res2.1.0.bias    |        512        |\n",
            "|   30  |   res2.1.1.weight   |        512        |\n",
            "|   31  |    res2.1.1.bias    |        512        |\n",
            "|   32  | classifier.3.weight |        5120       |\n",
            "|   33  |  classifier.3.bias  |         10        |\n",
            "+-------+---------------------+-------------------+\n",
            "Sum of trained paramters: 6575370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6575370"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUJZ3i3hBfiB",
        "outputId": "be02bfee-32be-4ad6-c024-b2f3681907f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6575370"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Calculate the total number of parameters\n",
        "total_params = sum(p.numel() for p in net.parameters())\n",
        "total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rjN-w1_CBI7",
        "outputId": "0df7f36c-3fc8-4670-e159-7f0b955e2c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in ResNet9 (including BatchNorm running mean and variance): 6579858\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total number of parameters, including BatchNorm running mean and variance\n",
        "state_dict = net.state_dict()\n",
        "total_params = sum(p.numel() for p in state_dict.values())\n",
        "print(f\"Total number of parameters in ResNet9 (including BatchNorm running mean and variance): {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zJTCqRep6DWE"
      },
      "outputs": [],
      "source": [
        "params = net.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_computation(num_partition):\n",
        "  handler = PartialModelHandler(num_partition)\n",
        "  num_parameters = len(handler.segment_resnet_parameters(handler.flatten_resnet_parameters(params))[0])\n",
        "\n",
        "\n",
        "  time_init_s = time.time()\n",
        "  enc_data = encrypt_data(context, handler.segment_resnet_parameters(handler.flatten_resnet_parameters(params))[0])\n",
        "  dec_data = decrypt_data(context, enc_data)\n",
        "  # Save the encrypted data using pickle\n",
        "  with open(f'resnet9_seg{num_partition}_encrypted_data.pkl', \"wb\") as f:\n",
        "      pickle.dump(enc_data.serialize(), f)\n",
        "  time_init_e = time.time()\n",
        "  computation_time = time_init_e-time_init_s\n",
        "\n",
        "  return num_parameters, computation_time"
      ],
      "metadata": {
        "id": "tJwaHoNaOwEA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_communication_bytes(file_path):\n",
        "\n",
        "  # Check the size of the file\n",
        "  file_size = os.path.getsize(file_path)\n",
        "\n",
        "  return file_size/(1024*1024)"
      ],
      "metadata": {
        "id": "_w8Zpe64PaIE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "partition_sizes = [1,2,3,4,5]\n",
        "for num in partition_sizes:\n",
        "  num_params, comp_time = calculate_computation(num)\n",
        "  print(f'For ParMS {num}, \\n \\t The total number of parameters is: {num_params}, \\n\\t The computation time is: {comp_time} seconds')\n",
        "  cipher_text_size = calculate_communication_bytes(f'resnet9_seg{num}_encrypted_data.pkl')\n",
        "  print(f'\\t The cipher text size is: {cipher_text_size}')\n",
        "  print(f'\\t The plain text size is {25.08/num}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81lfC646QIeR",
        "outputId": "1011804f-b5a2-4658-ed55-8223006e8bde"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
            "For ParMS 1, \n",
            " \t The total number of parameters is: 6579858, \n",
            "\t The computation time is: 25.21634602546692 seconds\n",
            "\t The cipher text size is: 512.2990703582764\n",
            "\t The plain text size is 25.08\n",
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
            "For ParMS 2, \n",
            " \t The total number of parameters is: 3289929, \n",
            "\t The computation time is: 12.560456037521362 seconds\n",
            "\t The cipher text size is: 256.30858612060547\n",
            "\t The plain text size is 12.54\n",
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
            "For ParMS 3, \n",
            " \t The total number of parameters is: 2193286, \n",
            "\t The computation time is: 7.655514478683472 seconds\n",
            "\t The cipher text size is: 170.8729944229126\n",
            "\t The plain text size is 8.36\n",
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
            "For ParMS 4, \n",
            " \t The total number of parameters is: 1644965, \n",
            "\t The computation time is: 6.874894380569458 seconds\n",
            "\t The cipher text size is: 128.1567668914795\n",
            "\t The plain text size is 6.27\n",
            "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
            "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
            "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
            "For ParMS 5, \n",
            " \t The total number of parameters is: 1315972, \n",
            "\t The computation time is: 4.409739255905151 seconds\n",
            "\t The cipher text size is: 102.6510591506958\n",
            "\t The plain text size is 5.016\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}